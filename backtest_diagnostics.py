#!/usr/bin/env python3
"""
BACKTEST DIAGNOSTICS - Diagn√≥stico profundo del sistema
Detecta look-ahead bias, analiza trades fallidos, compara distribuciones
"""
import pandas as pd
import json
from pathlib import Path
from datetime import datetime
from collections import Counter
import numpy as np


class BacktestDiagnostics:
    """Diagn√≥stico profundo del backtest"""

    def __init__(self):
        self.results_dir = Path("docs/backtest")
        self.diagnostics = {}

    def load_backtest_results(self):
        """Carga los resultados del backtest comprehensivo m√°s reciente"""
        # Buscar archivo m√°s reciente
        results_files = sorted(self.results_dir.glob("comprehensive_results_*.json"))

        if not results_files:
            print("‚ùå No se encontraron resultados de backtest")
            return None

        latest_file = results_files[-1]
        print(f"üìÇ Cargando: {latest_file}")

        with open(latest_file, 'r') as f:
            return json.load(f)

    def load_trades_detail(self):
        """Carga detalles de trades individuales si existen"""
        trades_files = sorted(self.results_dir.glob("trades_*.csv"))

        if trades_files:
            latest_trades = trades_files[-1]
            return pd.read_csv(latest_trades)
        return None

    def diagnose_lookahead_bias(self):
        """
        Diagn√≥stico 1: Detectar Look-Ahead Bias

        ¬øEstamos usando scores de HOY para simular trades de AYER?
        """
        print("\n" + "=" * 80)
        print("üî¨ DIAGN√ìSTICO 1: LOOK-AHEAD BIAS")
        print("=" * 80)

        # Cargar el CSV de scores actual
        scores_path = Path("docs/super_scores_ultimate.csv")

        if not scores_path.exists():
            print("‚ùå No se encontr√≥ super_scores_ultimate.csv")
            return

        df = pd.read_csv(scores_path)

        print(f"\nüìä Dataset: {len(df)} stocks con scores")
        print(f"   Columnas: {list(df.columns)}")

        # An√°lisis de timestamps
        if 'last_updated' in df.columns or 'timestamp' in df.columns:
            timestamp_col = 'last_updated' if 'last_updated' in df.columns else 'timestamp'
            print(f"\n‚úÖ Encontrado timestamp: {timestamp_col}")

            # Verificar cu√°ndo se generaron los scores
            if df[timestamp_col].notna().any():
                dates = pd.to_datetime(df[timestamp_col], errors='coerce')
                print(f"   üìÖ Scores generados el: {dates.max()}")
                print(f"   üìÖ Fecha m√°s antigua: {dates.min()}")
        else:
            print("\n‚ö†Ô∏è  NO hay columna de timestamp en los scores")
            print("   üö® PROBLEMA: No podemos verificar cu√°ndo se generaron los scores")
            print("   üö® Esto sugiere LOOK-AHEAD BIAS")

        # Verificar si hay columnas de datos hist√≥ricos
        historical_cols = [col for col in df.columns if 'historical' in col.lower() or '_date' in col.lower()]

        if historical_cols:
            print(f"\n‚úÖ Columnas hist√≥ricas encontradas: {historical_cols}")
        else:
            print("\n‚ö†Ô∏è  NO hay columnas hist√≥ricas expl√≠citas")
            print("   üí° Los scores parecen ser calculados con datos actuales")

        # An√°lisis del VCP score
        if 'vcp_score' in df.columns:
            print(f"\nüìà VCP Score:")
            print(f"   Media: {df['vcp_score'].mean():.2f}")
            print(f"   Max: {df['vcp_score'].max():.2f}")
            print(f"   Min: {df['vcp_score'].min():.2f}")

            # VCP score alto sugiere patrones actuales, no hist√≥ricos
            high_vcp = df[df['vcp_score'] > 30]
            print(f"   ‚ö†Ô∏è  {len(high_vcp)} stocks con VCP score > 30 (probablemente usando precios actuales)")

        # VEREDICTO
        print("\n" + "=" * 80)
        print("‚öñÔ∏è  VEREDICTO LOOK-AHEAD BIAS:")

        has_timestamps = 'last_updated' in df.columns or 'timestamp' in df.columns
        has_historical = len(historical_cols) > 0

        if not has_timestamps:
            print("üî¥ ALTO RIESGO de look-ahead bias:")
            print("   - No hay timestamps de cuando se generaron los scores")
            print("   - Probablemente usando datos actuales para simular trades pasados")
            print("   - Backtest results INFLADOS y NO confiables")
            bias_level = "HIGH"
        elif has_historical:
            print("üü¢ BAJO RIESGO de look-ahead bias:")
            print("   - Hay timestamps y columnas hist√≥ricas")
            print("   - Scoring parece usar datos hist√≥ricos")
            bias_level = "LOW"
        else:
            print("üü° RIESGO MEDIO de look-ahead bias:")
            print("   - Hay timestamps pero no columnas hist√≥ricas expl√≠citas")
            print("   - Necesita validaci√≥n manual del c√≥digo de scoring")
            bias_level = "MEDIUM"

        self.diagnostics['lookahead_bias'] = {
            'level': bias_level,
            'has_timestamps': has_timestamps,
            'has_historical_cols': has_historical,
            'recommendation': 'INVALIDATE BACKTEST' if bias_level == 'HIGH' else 'VALIDATE MANUALLY'
        }

        return bias_level

    def analyze_failed_trades_1y(self):
        """
        Diagn√≥stico 2: Analizar Trades Fallidos del Per√≠odo 1Y

        ¬øQu√© tienen en com√∫n las 47 p√©rdidas?
        """
        print("\n" + "=" * 80)
        print("üìâ DIAGN√ìSTICO 2: AN√ÅLISIS DE TRADES FALLIDOS (1Y)")
        print("=" * 80)

        # Cargar resultados del backtest
        results = self.load_backtest_results()

        if not results:
            return

        # Extraer trades del per√≠odo 1Y
        if 'Super Score Ultimate' not in results:
            print("‚ùå No se encontraron resultados de Super Score Ultimate")
            return

        ultimate_results = results['Super Score Ultimate']

        if '1 a√±o' not in ultimate_results:
            print("‚ùå No se encontraron resultados del per√≠odo 1 a√±o")
            return

        period_1y = ultimate_results['1 a√±o']
        backtest_data = period_1y['backtest']

        print(f"\nüìä Per√≠odo 1 A√±o:")
        print(f"   Total Trades: {backtest_data['total_trades']}")
        print(f"   Ganadores: {backtest_data['winning_trades']}")
        print(f"   Perdedores: {backtest_data['losing_trades']}")
        print(f"   Win Rate: {backtest_data['win_rate']:.1f}%")
        print(f"   Avg Return: {backtest_data['avg_return']:.2f}%")

        # Cargar CSV de scores para analizar
        scores_df = pd.read_csv("docs/super_scores_ultimate.csv")

        # Top tickers (asumiendo que son los que se testearon)
        top_tickers = scores_df.nlargest(55, 'super_score_ultimate')['ticker'].tolist()

        print(f"\nüîç Analizando {len(top_tickers)} tickers testeados...")

        # An√°lisis sectorial
        if 'sector' in scores_df.columns:
            tested_stocks = scores_df[scores_df['ticker'].isin(top_tickers)]
            sector_dist = tested_stocks['sector'].value_counts()

            print("\nüìä Distribuci√≥n Sectorial:")
            for sector, count in sector_dist.head(10).items():
                print(f"   {sector}: {count} stocks")

            # Calcular performance esperada por sector
            print("\nüí° HIP√ìTESIS: ¬øAlg√∫n sector falla m√°s?")
            print("   (Necesitar√≠amos trades individuales para confirmar)")

        # An√°lisis de scores
        if 'super_score_ultimate' in scores_df.columns:
            tested_stocks = scores_df[scores_df['ticker'].isin(top_tickers)]

            print(f"\nüìà Distribuci√≥n de Scores (Testeados):")
            print(f"   Media: {tested_stocks['super_score_ultimate'].mean():.2f}")
            print(f"   Mediana: {tested_stocks['super_score_ultimate'].median():.2f}")
            print(f"   Rango: {tested_stocks['super_score_ultimate'].min():.2f} - {tested_stocks['super_score_ultimate'].max():.2f}")

            # Scores por rango
            score_ranges = [
                (75, 100, "LEGENDARY"),
                (70, 75, "EXCELLENT"),
                (65, 70, "GOOD"),
            ]

            print(f"\n   Distribuci√≥n por Rango:")
            for min_s, max_s, label in score_ranges:
                count = len(tested_stocks[(tested_stocks['super_score_ultimate'] >= min_s) &
                                         (tested_stocks['super_score_ultimate'] < max_s)])
                print(f"   {label} ({min_s}-{max_s}): {count} stocks")

        # HIP√ìTESIS sobre fallos
        print("\n" + "=" * 80)
        print("üí° HIP√ìTESIS SOBRE FALLOS:")
        print("=" * 80)

        print("\n1. üî¥ MARKET REGIME CHANGE (1 a√±o atr√°s)")
        print("   - Hace 1 a√±o (Feb 2025): ¬øMercado diferente?")
        print("   - Posibles factores: tasas inter√©s, inflaci√≥n, sector rotation")

        print("\n2. üî¥ HOLD PERIODS DEMASIADO LARGOS")
        print("   - Hold 30-90 d√≠as en mercado de hace 1 a√±o")
        print("   - Puede capturar drawdowns completos")

        print("\n3. üî¥ SCORING OPTIMIZADO PARA HOY")
        print("   - VCP patterns actuales ‚â† VCP patterns de hace 1 a√±o")
        print("   - ML model entrenado en datos recientes")
        print("   - Fundamentales 'fuertes' hoy ‚â† predictivos hace 1 a√±o")

        self.diagnostics['failed_trades_1y'] = {
            'total_trades': backtest_data['total_trades'],
            'losing_trades': backtest_data['losing_trades'],
            'win_rate': backtest_data['win_rate'],
            'avg_return': backtest_data['avg_return'],
            'top_hypothesis': 'MARKET_REGIME_CHANGE'
        }

    def compare_score_distributions(self):
        """
        Diagn√≥stico 3: Comparar Distribuci√≥n de Scores

        ¬øLos scores "altos" significan lo mismo en 3M vs 6M vs 1Y?
        """
        print("\n" + "=" * 80)
        print("üìä DIAGN√ìSTICO 3: COMPARACI√ìN DE DISTRIBUCIONES")
        print("=" * 80)

        results = self.load_backtest_results()

        if not results:
            return

        # Analizar cada per√≠odo
        periods_data = {}

        for dataset_name, periods in results.items():
            if dataset_name != "Super Score Ultimate":
                continue

            print(f"\nüéØ Dataset: {dataset_name}")
            print("-" * 80)

            for period_name, data in periods.items():
                backtest = data['backtest']

                print(f"\nüìÖ Per√≠odo: {period_name}")
                print(f"   Trades: {backtest['total_trades']}")
                print(f"   Win Rate: {backtest['win_rate']:.1f}%")
                print(f"   Avg Return: {backtest['avg_return']:.2f}%")
                print(f"   Sharpe: {backtest['sharpe_ratio']:.2f}")

                periods_data[period_name] = {
                    'win_rate': backtest['win_rate'],
                    'avg_return': backtest['avg_return'],
                    'sharpe': backtest['sharpe_ratio']
                }

        # An√°lisis de tendencias
        print("\n" + "=" * 80)
        print("üìà AN√ÅLISIS DE TENDENCIAS:")
        print("=" * 80)

        if len(periods_data) >= 3:
            periods_list = ['3 meses', '6 meses', '1 a√±o']

            print("\nüîª Degradaci√≥n de M√©tricas:")

            for metric in ['win_rate', 'avg_return', 'sharpe']:
                print(f"\n   {metric.upper()}:")

                for i, period in enumerate(periods_list):
                    if period in periods_data:
                        value = periods_data[period][metric]

                        # Calcular cambio vs per√≠odo anterior
                        if i > 0:
                            prev_period = periods_list[i-1]
                            if prev_period in periods_data:
                                prev_value = periods_data[prev_period][metric]
                                change = value - prev_value
                                pct_change = (change / abs(prev_value) * 100) if prev_value != 0 else 0

                                print(f"   {period}: {value:.2f} (Œî {change:+.2f}, {pct_change:+.1f}%)")
                        else:
                            print(f"   {period}: {value:.2f}")

        # CONCLUSI√ìN
        print("\n" + "=" * 80)
        print("üí° CONCLUSI√ìN:")
        print("=" * 80)

        # Calcular degradaci√≥n promedio
        if '3 meses' in periods_data and '1 a√±o' in periods_data:
            wr_3m = periods_data['3 meses']['win_rate']
            wr_1y = periods_data['1 a√±o']['win_rate']
            degradation = wr_3m - wr_1y

            print(f"\nüî¥ Degradaci√≥n Total (3M ‚Üí 1Y):")
            print(f"   Win Rate: -{degradation:.1f} puntos ({wr_3m:.1f}% ‚Üí {wr_1y:.1f}%)")

            if degradation > 50:
                print(f"\n   ‚ö†Ô∏è  DEGRADACI√ìN SEVERA (>{50}pts)")
                print(f"   üö® Sistema NO es robusto temporalmente")
                print(f"   üö® Scoring est√° overfitted a condiciones recientes")
            elif degradation > 30:
                print(f"\n   ‚ö†Ô∏è  Degradaci√≥n significativa (30-50pts)")
                print(f"   üí° Necesita ajustes de robustez")
            else:
                print(f"\n   ‚úÖ Degradaci√≥n aceptable (<30pts)")

        self.diagnostics['score_distribution'] = {
            'periods': periods_data,
            'degradation': degradation if 'degradation' in locals() else None
        }

    def generate_diagnostic_report(self):
        """Genera reporte final de diagn√≥stico"""
        print("\n" + "=" * 80)
        print("üìã REPORTE DE DIAGN√ìSTICO")
        print("=" * 80)

        # Guardar diagn√≥stico
        output_dir = Path("docs/diagnostics")
        output_dir.mkdir(parents=True, exist_ok=True)

        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        output_file = output_dir / f"backtest_diagnostics_{timestamp}.json"

        with open(output_file, 'w') as f:
            json.dump(self.diagnostics, f, indent=2)

        print(f"\nüíæ Diagn√≥stico guardado: {output_file}")

        # Resumen ejecutivo
        print("\n" + "=" * 80)
        print("üéØ RESUMEN EJECUTIVO:")
        print("=" * 80)

        if 'lookahead_bias' in self.diagnostics:
            bias_level = self.diagnostics['lookahead_bias']['level']

            if bias_level == "HIGH":
                print("\nüî¥ LOOK-AHEAD BIAS: ALTO RIESGO")
                print("   ‚ö†Ô∏è  Backtest results probablemente INFLADOS")
                print("   ‚ö†Ô∏è  NO confiar en m√©tricas reportadas")
                print("   üîß ACCI√ìN: Re-implementar scoring con datos hist√≥ricos")
            elif bias_level == "MEDIUM":
                print("\nüü° LOOK-AHEAD BIAS: RIESGO MEDIO")
                print("   üí° Validar manualmente c√≥digo de scoring")
                print("   üí° Verificar que usa solo datos hist√≥ricos")
            else:
                print("\nüü¢ LOOK-AHEAD BIAS: BAJO RIESGO")
                print("   ‚úÖ Scoring parece usar datos hist√≥ricos")

        if 'failed_trades_1y' in self.diagnostics:
            wr_1y = self.diagnostics['failed_trades_1y']['win_rate']

            print(f"\nüìâ TRADES FALLIDOS (1Y):")
            print(f"   Win Rate: {wr_1y:.1f}% (Target: ‚â•55%)")

            if wr_1y < 20:
                print(f"   üî¥ Performance CATASTR√ìFICA")
                print(f"   üí° Hip√≥tesis: Market regime change + hold periods largos")

        if 'score_distribution' in self.diagnostics:
            degradation = self.diagnostics['score_distribution'].get('degradation')

            if degradation:
                print(f"\nüìä DEGRADACI√ìN TEMPORAL:")
                print(f"   3M ‚Üí 1Y: -{degradation:.1f} puntos de win rate")

                if degradation > 50:
                    print(f"   üî¥ SEVERA: Sistema overfitted a corto plazo")

        # RECOMENDACIONES FINALES
        print("\n" + "=" * 80)
        print("üéØ RECOMENDACIONES FINALES:")
        print("=" * 80)

        print("\n1. üö® PRIORIDAD ALTA:")

        if self.diagnostics.get('lookahead_bias', {}).get('level') == 'HIGH':
            print("   - Fix look-ahead bias INMEDIATAMENTE")
            print("   - Re-implementar scoring con datos hist√≥ricos punto-en-tiempo")
            print("   - Invalidar resultados actuales del backtest")
        else:
            print("   - Reducir hold periods a 10-30 d√≠as m√°ximo")
            print("   - Implementar stops agresivos (-8% a -10%)")
            print("   - Agregar market regime filter")

        print("\n2. üîß FIXES T√âCNICOS:")
        print("   - Walk-forward validation del ML model")
        print("   - Regime detection (bull/bear/choppy)")
        print("   - Scoring din√°mico basado en r√©gimen")

        print("\n3. ‚è±Ô∏è TIMELINE:")
        print("   - Diagn√≥stico completado: ‚úÖ")
        print("   - Fix look-ahead bias: 1 semana")
        print("   - Implementar stops/regime: 2-3 semanas")
        print("   - Re-validaci√≥n: 1 semana")
        print("   - Total: ~1 mes para sistema confiable")

        print("\n" + "=" * 80)


def main():
    """Main execution"""
    print("üî¨ BACKTEST DIAGNOSTICS - Diagn√≥stico Profundo")
    print("=" * 80)

    diagnostics = BacktestDiagnostics()

    # Ejecutar diagn√≥sticos
    diagnostics.diagnose_lookahead_bias()
    diagnostics.analyze_failed_trades_1y()
    diagnostics.compare_score_distributions()
    diagnostics.generate_diagnostic_report()

    print("\n‚úÖ DIAGN√ìSTICO COMPLETADO")
    print("=" * 80)


if __name__ == "__main__":
    main()

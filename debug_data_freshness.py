#!/usr/bin/env python3
"""
Script para diagnosticar por quÃ© los datos de insider trading no se actualizan
"""

import pandas as pd
import os
from datetime import datetime, timedelta

def diagnosticar_datos_insider():
    """
    Diagnostica el estado de los datos de insider trading
    """
    print("ğŸ” DIAGNÃ“STICO DE DATOS DE INSIDER TRADING")
    print("=" * 60)
    print(f"ğŸ“… Fecha actual: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    # Verificar archivo principal
    csv_path = "reports/insiders_daily.csv"
    
    if not os.path.exists(csv_path):
        print(f"âŒ El archivo {csv_path} no existe")
        return
    
    # InformaciÃ³n del archivo
    stat = os.stat(csv_path)
    file_modified = datetime.fromtimestamp(stat.st_mtime)
    file_size = stat.st_size
    
    print(f"ğŸ“„ Archivo: {csv_path}")
    print(f"ğŸ“… Ãšltima modificaciÃ³n: {file_modified.strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸ“ TamaÃ±o: {file_size:,} bytes")
    print(f"â° Hace: {datetime.now() - file_modified}")
    print()
    
    # Verificar si es de hoy
    hoy = datetime.now().date()
    archivo_date = file_modified.date()
    
    if archivo_date == hoy:
        print("âœ… El archivo ES de hoy")
    elif archivo_date == hoy - timedelta(days=1):
        print("âš ï¸ El archivo es de AYER")
    else:
        print(f"âŒ El archivo es de {archivo_date} (MUY ANTIGUO)")
    print()
    
    # Leer y analizar contenido
    try:
        df = pd.read_csv(csv_path)
        print(f"ğŸ“Š Datos leÃ­dos: {len(df)} filas, {len(df.columns)} columnas")
        print(f"ğŸ·ï¸ Columnas: {list(df.columns)}")
        print()
        
        # Analizar fechas en los datos
        if 'ScrapedAt' in df.columns:
            print("ğŸ“… AnÃ¡lisis de fechas ScrapedAt:")
            df['ScrapedAt'] = pd.to_datetime(df['ScrapedAt'], errors='coerce')
            
            fechas_unicas = df['ScrapedAt'].dt.date.value_counts().sort_index()
            print("Fechas en los datos:")
            for fecha, count in fechas_unicas.items():
                if fecha == hoy:
                    print(f"  âœ… {fecha}: {count} registros (HOY)")
                elif fecha == hoy - timedelta(days=1):
                    print(f"  âš ï¸ {fecha}: {count} registros (AYER)")
                else:
                    print(f"  âŒ {fecha}: {count} registros (ANTIGUO)")
        
        # Analizar timestamps de transacciones
        if 'Ticker' in df.columns:
            print("\nğŸ•’ AnÃ¡lisis de timestamps de transacciones:")
            # En tu estructura, 'Ticker' contiene el timestamp
            timestamps = pd.to_datetime(df['Ticker'], errors='coerce')
            valid_timestamps = timestamps.dropna()
            
            if len(valid_timestamps) > 0:
                fecha_min = valid_timestamps.min().date()
                fecha_max = valid_timestamps.max().date()
                
                print(f"  ğŸ“… Rango de fechas: {fecha_min} a {fecha_max}")
                
                # Contar por dÃ­a
                fechas_transacciones = valid_timestamps.dt.date.value_counts().sort_index()
                for fecha, count in fechas_transacciones.items():
                    if fecha == hoy:
                        print(f"  âœ… {fecha}: {count} transacciones (HOY)")
                    elif fecha == hoy - timedelta(days=1):
                        print(f"  âš ï¸ {fecha}: {count} transacciones (AYER)")
                    else:
                        print(f"  âŒ {fecha}: {count} transacciones")
        
        # Mostrar muestra de datos
        print("\nğŸ“‹ Muestra de primeros 3 registros:")
        for i in range(min(3, len(df))):
            row = df.iloc[i]
            timestamp = row.get('Ticker', 'N/A')
            ticker = row.get('Insider', 'N/A')
            company = row.get('Title', 'N/A')
            scraped = row.get('ScrapedAt', 'N/A')
            print(f"  {i+1}. {timestamp} | {ticker} | {company} | Scraped: {scraped}")
            
    except Exception as e:
        print(f"âŒ Error leyendo CSV: {e}")
    
    print("\n" + "=" * 60)
    print("ğŸ”§ POSIBLES SOLUCIONES:")
    print("=" * 60)
    
    if archivo_date != hoy:
        print("1. ğŸ”„ El scraper de OpenInsider no se ejecutÃ³ hoy")
        print("   - Verificar que openinsider_scraper.py se ejecute correctamente")
        print("   - Revisar logs del scraper")
        print("   - Ejecutar manualmente el scraper")
    
    print("2. ğŸ“‚ Verificar ubicaciÃ³n del archivo")
    print("   - Â¿El scraper estÃ¡ guardando en la ubicaciÃ³n correcta?")
    print("   - Â¿Hay mÃºltiples copias del archivo?")
    
    print("3. â° Verificar horarios de ejecuciÃ³n")
    print("   - Â¿El anÃ¡lisis se ejecuta antes que el scraper?")
    print("   - Â¿Hay conflictos de horarios?")
    
    print("4. ğŸ”„ Forzar actualizaciÃ³n manual")
    print("   - Ejecutar openinsider_scraper.py manualmente")
    print("   - Verificar que genera datos nuevos")

def verificar_scraper():
    """
    Verifica el estado del scraper de OpenInsider
    """
    print("\nğŸ•·ï¸ VERIFICACIÃ“N DEL SCRAPER")
    print("=" * 40)
    
    posibles_scrapers = [
        "openinsider_scraper.py",
        "insiders/openinsider_scraper.py", 
        "scrapers/openinsider_scraper.py",
        "scripts/openinsider_scraper.py"
    ]
    
    scraper_encontrado = None
    for scraper_path in posibles_scrapers:
        if os.path.exists(scraper_path):
            print(f"âœ… Scraper encontrado: {scraper_path}")
            scraper_encontrado = scraper_path
            break
    
    if not scraper_encontrado:
        print("âŒ No se encontrÃ³ el scraper de OpenInsider")
        print("   Posibles ubicaciones buscadas:")
        for path in posibles_scrapers:
            print(f"   - {path}")
        return None
    
    # Verificar Ãºltima modificaciÃ³n del scraper
    stat = os.stat(scraper_encontrado)
    scraper_modified = datetime.fromtimestamp(stat.st_mtime)
    
    print(f"ğŸ“… Ãšltima modificaciÃ³n del scraper: {scraper_modified.strftime('%Y-%m-%d %H:%M:%S')}")
    
    return scraper_encontrado

def ejecutar_test_scraper(scraper_path):
    """
    Ejecuta un test del scraper
    """
    if not scraper_path:
        return
        
    print(f"\nğŸ§ª Â¿Quieres ejecutar el scraper manualmente para obtener datos frescos?")
    respuesta = input("Escribe 'si' para ejecutar: ").lower().strip()
    
    if respuesta in ['si', 'sÃ­', 's', 'yes', 'y']:
        try:
            print(f"ğŸ”„ Ejecutando {scraper_path}...")
            import subprocess
            result = subprocess.run(['python3', scraper_path], 
                                  capture_output=True, text=True, timeout=60)
            
            if result.returncode == 0:
                print("âœ… Scraper ejecutado exitosamente")
                print("ğŸ“„ Output:")
                print(result.stdout)
                
                # Verificar si se generaron datos nuevos
                print("\nğŸ” Verificando datos actualizados...")
                diagnosticar_datos_insider()
                
            else:
                print("âŒ Error ejecutando scraper")
                print("Error output:")
                print(result.stderr)
                
        except subprocess.TimeoutExpired:
            print("â° Timeout ejecutando scraper")
        except Exception as e:
            print(f"âŒ Error: {e}")

if __name__ == "__main__":
    # DiagnÃ³stico principal
    diagnosticar_datos_insider()
    
    # Verificar scraper
    scraper_path = verificar_scraper()
    
    # OpciÃ³n de ejecutar scraper
    ejecutar_test_scraper(scraper_path)
    
    print("\nğŸ¯ RECOMENDACIONES:")
    print("1. AsegÃºrate de que el scraper se ejecute ANTES del anÃ¡lisis")
    print("2. Verifica que no hay errores en el scraper")  
    print("3. Considera ejecutar el scraper manualmente para probar")
    print("4. Revisa los logs del cron para ver si hay errores")